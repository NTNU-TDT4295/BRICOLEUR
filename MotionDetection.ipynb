{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "from pynq.lib import DMA\n",
    "from pynq import MMIO\n",
    "from pynq import Xlnk\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "ol = Overlay(\"/home/xilinx/rosetta/design_1.bit\")\n",
    "ol.download()\n",
    "\n",
    "dma = ol.axi_dma_0\n",
    "\n",
    "#import cv2\n",
    "\n",
    "#img1 = cv2.imread('1.jpg')\n",
    "#img2 = cv2.imread('2.jpg')\n",
    "#img3 = cv2.imread('3.jpg')\n",
    "\n",
    "height = 238\n",
    "width = 318\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video = cv2.VideoWriter(\"/home/xilinx/output_video.avi\",fourcc,30,(width,height))\n",
    "\n",
    "#video.write(img1)\n",
    "#video.write(img2)\n",
    "#video.write(img3)\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "#video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python motion_detector.py\n",
    "# python motion_detector.py --video videos/example_01.mp4\n",
    "\n",
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-v\", \"--video\", default=\"~/rosetta/example_02.mp4\",help=\"path to the video file\")\n",
    "#ap.add_argument(\"-a\", \"--min-area\", type=int, default=500, help=\"minimum area size\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# if the video argument is None, then we are reading from webcam\n",
    "args={\"video\": \"/home/xilinx/rosetta/example_02.mp4\", \"min-area\":500}\n",
    "\n",
    "if args.get(\"video\", None) is None:\n",
    "    vs = VideoStream(src=0).start()\n",
    "    time.sleep(2.0)\n",
    "\n",
    "# otherwise, we are reading from a video file\n",
    "else:\n",
    "    vs = cv2.VideoCapture(args[\"video\"])\n",
    "    #print(vs)\n",
    "#vs = cv2.VideoCapture(args[\"video\"])\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "#frameBuffer = Xlnk().cma_array(shape=(720, 1152, 3), dtype=np.uint8)\n",
    "frameBuffer = Xlnk().cma_array(shape=(240, 320, 3), dtype=np.uint32)\n",
    "frameBufferOut = Xlnk().cma_array(shape=(238, 318, 3), dtype=np.uint32)\n",
    "maxIterations = 50\n",
    "i = 0\n",
    "# loop over the frames of the video\n",
    "while True:\n",
    "    i += 1\n",
    "    if i>maxIterations:\n",
    "        break\n",
    "    # grab the current frame and initialize the occupied/unoccupied\n",
    "    # text\n",
    "    #print(frameBuffer)\n",
    "    #print(vs.read(frameBuffer))\n",
    "    frame =vs.read()[1]\n",
    "    \n",
    "    #print(frameBuffer)\n",
    "    #exit()\n",
    "    #help(vs.read)\n",
    "    #exit()\n",
    "    #help(vs.read()[1])\n",
    "    #print(type(frame))\n",
    "    #frameBuffer.pointer =  if args.get(\"video\", None) is None else frame[1]\n",
    "    #text = \"Unoccupied\"\n",
    "    # if the frame could not be grabbed, then we have reached the end\n",
    "    # of the vide\n",
    "    #print(\"Start of iteration of while\")\n",
    "    #print(frame)\n",
    "    \n",
    "    if frame is None:\n",
    "        print(\"Within break block\")\n",
    "        break\n",
    "\n",
    "    # resize the frame, convert it to grayscale, and blur it\n",
    "    \n",
    "    ####################\n",
    "    \n",
    "    frame = cv2.resize(frame, (320,240))\n",
    "    np.copyto(frameBuffer, frame)\n",
    "    #print(\"Before wait\")\n",
    "    dma.sendchannel.transfer(frameBuffer)\n",
    "    dma.recvchannel.transfer(frameBufferOut)\n",
    "    dma.sendchannel.wait()\n",
    "    dma.recvchannel.wait()\n",
    "    \n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    ########################\n",
    "    \n",
    "    \n",
    "    # if the first frame is None, initialize it\n",
    "    if firstFrame is None:\n",
    "        firstFrame = frameBufferOut\n",
    "        #continue\n",
    "        pass\n",
    "    \"\"\"\n",
    "    # compute the absolute difference between the current frame and\n",
    "    # first frame\n",
    "    frameDelta = cv2.absdiff(firstFrame, frameBuffer)\n",
    "    thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # dilate the thresholded image to fill in holes, then find contours\n",
    "    # on thresholded image\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "   \n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "\n",
    "    # loop over the contours\n",
    "    \n",
    "    for c in cnts:\n",
    "        # if the contour is too small, ignore it\n",
    "        if cv2.contourArea(c) < args[\"min-area\"]:\n",
    "            #continue\n",
    "            pass\n",
    "    \n",
    "        # compute the bounding box for the contour, draw it on the frame,\n",
    "        # and update the text\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(frameBuffer, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        #text = \"Occupied\"\n",
    "    \"\"\"\n",
    "    # draw the text and timestamp on the frame\n",
    "    #cv2.putText(frame, \"Room Status: {}\".format(text), (10, 20),\n",
    "    #            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    #cv2.putText(frame, datetime.datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),\n",
    "    #            (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "    # show the frame and record if the user presses a key\n",
    "    #cv2.imshow(\"Security Feed\", frame)\n",
    "    #cv2.imshow(\"Thresh\", thresh)\n",
    "    #cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "   \n",
    "    \n",
    "    #key = cv2.waitKey(1) & 0xFF\n",
    "    #print(frameBuffer.dtype)\n",
    "    cv2.imwrite(\"/home/xilinx/image_dump/opencv_image_\"+str(i)+\".png\", frameBufferOut.astype(np.uint8))\n",
    "    #video.write(frameBufferOut.astype(np.uint8))\n",
    "    # if the `q` key is pressed, break from the lop\n",
    "    #if key == ord(\"q\"):\n",
    "    #    break\n",
    "    \n",
    "    \n",
    "# cleanup the camera and close any open windows\n",
    "vs.stop() if args.get(\"video\", None) is None else vs.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "frameBuffer.close()\n",
    "frameBufferOut.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlnk().xlnk_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
